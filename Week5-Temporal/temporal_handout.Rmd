---
title: 'Handout: Temporal Diversity'
author: 'Z620: Quantitative Biodiversity, Indiana University'
date: "February 10, 2017"
header-includes:
   - \usepackage{array}
output: pdf_document
geometry: margin=2.54cm
---

## OVERVIEW

In this exercise, we will explore aspects of temporal diversity. 
Biological systems are inherently variable thorugh time.
While some of this variation is stochastic, ecological systems can change though time owing to abiotic drivers (e.g., rising temperature, increasing CO~2~, drought) or biological processes (e.g., invasive species, disease). 
While some biodiversity scientists may be attracted processes that occur on contemporary scales (minutes, days, weeks, years), other scientists are interested in what drives patterns of biodiversity in the fossil record over geologic time scales. 
In this module, we will first introduce you to a new ecological data structure, the time-by-site-species matrix.
You will learn how to manage and manipulate this data structure, while also dealing with features such as non-stationarity and non-independence that are common in time series datasets. 
Finally, we will review ecological concepts such as community turnover and temporal beta diversity. 

## 1) SETUP
### Retrieve and Set Your Working Directory

```{r, results = 'hide'}
rm(list=ls()) 
getwd() 
setwd("~/GitHub/QuantitativeBiodiversity/QB-2017/Week5-Temporal/") 
```

### Install Packages

We will be using several packages in this week's module. 
Let's load them now. 
The `require()` function in `R` returns `TRUE` if the package was successfully loaded or `FALSE` if the package failed to load. 
This `for` loop loads each package and installs the package when `require()` returns `FALSE`.

```{r, results = 'hide', message = FALSE, warning = FALSE} 
package.list <- c('vegan', 'tidyr', 'dplyr', 'codyn', 'ggplot2', 'cowplot', 'MullerPlot', 'RColorBrewer', 'reshape2', 'lubridate', 'TTR', 'xtable', 'multcomp')
for (package in package.list) {
  if (!require(package, character.only=T, quietly=T)) {
    install.packages(package)
    library(package, character.only=T)
  }
}
```

## 2) LOADING DATA

To learn about topics of temporal biodiversity, we will be using the long-term monitoring dataset of rodents from the Chihuahuan Desert ecosystem near Portal, Arizona.
Known as the "Portal Project" <http://portal.weecology.org/>, this biodiversity study was initiatied in the late 1970s by Jim Brown and colleagues to look at species interactions, specifically competition between rodents and ants for plant seeds.
Early experiments focused on the exclusion of rodents with fencing and trapping, which led to an increase in the ant population size as well as changes in plant species composition.
These findings inspired Brown and colleagues to construct an improved experiment that continues today. 
The Portal Project monitors 24 replicated experimental plots, each 0.25 ha in area (50 X 50 m).
In total, 4.8 kilometers of fencing is used in the Portal experiment!

Let's take a look at the data:

```{r}
portal <- read.table("data/combined.csv", sep = ",", header = TRUE)
```

The version of the data that we are working with spans from 1977 - 2002. 
During this period, individual rodents were captured from plots ("plot_id"), identified to species ("species_id"), which led to the creation of a "record_id" with an associated date (day, month, and year).
In addition, the sex, size ("hindfoot_length" and "weight") and taxonomic identity ("genus" and "species") of each animal was recorded. 
All of this was done in five experimentally replicated treatments: 

1) Controls - fencing around plots does not exclude rodents (plot_id: 2, 4, 8, 11, 12, 14, 17, 22) 

2) Long-term Krat - long-term exclusion of Kangaroo rats (*Dipodomys merriami*) (plot_id: 3, 15, 19, 21) 

3) Short-term Krat - short-term exclusion of Kangaroo rats (*Dipodomys merriami*) (plot_id: 6, 13, 18, 20) 

4) Rodent Exclosure - exclusions of all rodents (plot_id: 5, 7, 10, 16, 23, 24) 

5) Spectab exclosure - exclusion of Banner-tailed kangaroo rat (*Dipodomys spectabilis*) (plot_id: 1, 9) 

## 3) MANAGING AND MANIPULATING DATA

The Portal Project is a great example of a long-term biodiversity project. 
The success of the Portal Project is based not only on the generation of a lot of quality data, but also the organization and proper management of these data. 
One thing you may notice when looking at `portal` is that it has a lot of observations, almost 35,000.
These data are entered in *long format*, which means that, as described above, each row represents a unique observation. 
The long format is a convenient way to enter data that reduces entry errors.
However, you need to manipulate the data for visualization and statistical analysis. 
For example, many R packages and functions will want you to organize your data in *wide format* where, for example, different sampling time points would be represented in columns.

In the following sections, we will demonstate how to manipulate the `portal` data set to carry out different types of analyses using functions from the `dplyr` and `tidyr` packages, which were designed for transforming and summarizing tabular data.
The functions contained in these two packages (and others) are preferred ways for manipulating data in R compared to other control-flow statements that are commonly used in programming (e.g., for loops)

First, let's use the `unite()` function from the `tidyr` package to create new columns that contain information in other columns. 

```{r}
# Make a date column that contins year, month, and day
portal <- unite(portal, col = date, c(year, month, day), sep = "-", remove = FALSE)

# Make a taxon column that contains genus and species names
portal <- unite(portal, col = taxon, c(genus, species), sep = "_", remove = FALSE)
```

Now, we are going to use `dplyr` to create a time-by-species matrix. 
We will use a new operator referred to as "pipes" (%>%). 
Pipes allow output from one function to be used as input for another function.
When using pipes, you use the output from the function to left to feed into the next function to the right. 
To build the time-by-species matrix, we we also be using a `dplyr` function called `group_by`, which splits the dataset up using a single or multiple variables.
After this, `dplyr` allow one to apply functions to the split datset using functions like `summarise()`, which can return summary statistics (e.g., mean, min, max).
You can also use the `spread()` function from `tidyr` on the split dataset to convert a parts of a long format dataset to a wide format dataset. 


```{r}
# `count` sums individuals in a taxon
# fill argument assigns value of 0 if there are no values for a combination
time.by.species <- group_by(portal, year, plot_id) %>% count(taxon) %>% spread(key = taxon, value = n, fill = 0)

# Convert tidyr object to a dataframe
time.by.species <- as.data.frame(time.by.species)

# NW: Not sure what below was intended to do, but year can't be rownames because they repeat <== right, we added plot_id to the group_by function, so we know have site-by-species info across years. 
# Use first column of dataframe as row names
# rownames(time.by.species) <- time.by.species[,1]
# time.by.species <- time.by.species[,-1]
```

## 4) BASIC TIME SERIES ANALYSIS

Because many questions in biodiversity science involve time, we are going to provide a brief overview of time series analysis.
Time series analysis involves statistical tools for detecting and decomposing trends in temporal data.
There are a number of important features and assumptions that one must consider when analyzing time series data. 
For example, one common assumption that must be met when peforming time series analysis is that your data must be **stationary**. 
In brief, this means that the mean, variance, and covariance of your data should not be a function of time.
If the assumption of stationarity is not met, you need to take corrective measures, which could invovle transforming or differencing (t - 1) the data. 
In the following sections, we provide a primer of time series analysis using the abundance of rodents in a single site of the Portal Project.
The Chihuahuan Desert sits in a rain shadow created by the Sierra Madre mountains.
As a result, the Portal site is dry with rain falling primarily in June through October.
We will try to detect a signal of this seasonality in our dataset, while detectign long-term trends and forecasting rodent densities into the future.
Let's get started by manipulating our data using some of the tools that we introduced above from the `dplyr` and `tidyr` packages.

```{r}
# Create a time-by-species matrix that includes year, month, and plot_id
time.by.spec.2 <- group_by(portal, year, month, plot_id) %>% count(taxon) 

# Create a seasonality variable using month number
time.by.spec.2$season <- NA
time.by.spec.2$season <- time.by.spec.2$month %in% c(6:10)

# Rainy seasons are June - October
time.by.spec.2$season <- ifelse(time.by.spec.2$season == TRUE, "rain", "norain")

# Group the data by year and season
group_by(time.by.spec.2, year, season)

# Pict a plot and then calculate rodent abundance for each season with a year 
abund <- filter(time.by.spec.2, plot_id == 5) %>% group_by(year, season) %>% count(wt = n)

# Correct abundances to express on a per hectare basis
abund$nn <- abund$nn * 4
```

Now, we are going to use a set of time series functions in the R base package. 
The first thing we will do is create a time series data set, which identifies the start time and seasonality of our sampling.

```{r}
# Define the time series and frequency (i.e., number of observations per year)
ab.ts <- ts(abund$nn, frequency = 2, start = c(1977, 2))

# Let's look at a plot of the data
plot.ts(ab.ts, ylab = "Rodent Abundance (#/hectrare)", xlab = "Time (year)", las = 1)
```

Now, peform some analyses to see whether our data meet the assumption of stationarity. 
The first thing we will do is use the *autocorrelation function (ACF)*, which effectively looks at the strength of correlation with itself over lagged time intervals.
Similarly, we will use the *partial autocorrelation function (PACF)*, which controls for values of shorter lag times. 
In both cases, if a time series is stationary, the correlation of lagged time points will quickly decay. 
Last, we will use a *Ljung-Box* test, which effectively tests for randomness in a string of observations. 

```{r}
acf(ab.ts) # autocorrelation function
pacf(ab.ts) # partial autocorrelation function
Box.test(ab.ts, lag = 10, type = "Ljung-Box") # small p-values ~ stationary
```

Together, the above analyses suggest that our data can most likely be fit with and additive model and that transformations or differencing is not required. 
One technique that is commonly used, mostly for visualization purposes, is *smoothing*. 
These types of techniques are used as low-pass filters that effectively remove noise from a data set, and aid in the visualization of signal in your dataset.
In the follow chunk of code we will use a simple moving average procedure from the `TTR` package. 
The function `sma()` calculates the arithmetic mean of the time series over the past *n* observations.
this unweighted, moving average approach smooths data with increasing *n*. 
Try out the code below and play around with *n*.

```{r{}} 
ab.ts.sm <- SMA(ab.ts, n = 8)
plot.ts(ab.ts.sm, ylab = "Rodent Abundance (#/hectrare)", xlab = "Time (year)", las = 1)

ab.ts.hw <- HoltWinters(ab.ts, beta = FALSE, gamma = FALSE)
ab.ts.hw$fitted
plot(ab.ts.hw, xlab = "Time (year)", las = 1, main = NA)


# ab.ts.2 <- forecast.HoltWinters(abund$nn, h = 19)
# plot.forecast(ab.ts.2)
```

As mentioned above, we sampled subsampled the `portal` data set so that it included seasonal variation that could be driven by patterns of precipitation. 
In the following section we will use the `decompose()` function which decomposes the time series so that we can assess contributions from the overal trend, seasonality, and radom processes.
If seasonal trends are a nuisance in your study, there are ways to remove them, as done in the chunk below. 

```{r{}
ab.comp <- decompose(ab.ts) # moving average decomposition
plot(ab.comp) 

ab.adj <- ab.ts - ab.comp$seasonal # remove seasonality
plot.ts(ab.adj, ylab = "Rodent Abundance (#/hectrare)", xlab = "Time (year)", las = 1)
```

Last, we will use an autoregressive integrated moving averge (ARIMA) approach to model our data.
ARIMA models predict a response variable based on regressing observations with past, lagged observations using linear comibiantion of error terms from the combinations of time points. 
ARIMA models accept parameters (*p*, *d*, and *q*) that describe the number of lags , differencing, and order of the moving-averge model, respectively. 
ARIMA models can also be used for forecasting into the future based on processes that fit the observed time series, as shown below. 
Obviously, the reliability of forecast diminshes with time as it's not being updated with new information. 

```{r}
ab.arm <- arima((ab.ts), c(0, 0, 1), seasonal = list(order = c(0, 1, 1), period = 2))
pred.arm <- predict(arm, n.ahead = 10*2)
ts.plot(ab.ts, pred.arm$pred, lty = c(1,3))
```

## 5) REPEATED MEASURES ANALYSIS OF VARIANCE (RM-ANOVA)
When scientists go to the trouble of setting up an experiment, whether it be in a laboratory, a hospital, or in the field, they tend to take more than one measurement on their experimental unit. 
Such studies are referred to as *longitudinal designs*.
Historically, there has been confusion about how to deal with the fact that these meausrements are non-indepdent and thus violate some of the major assumptions of most parameteric statistics. 
Repeated measures Analysis of Variance (ANOVA) provides on way of analyzing factorically designed longitudinal studies. 
In the following sectionn, we will show you how to peform and interpret a RM-ANOVA using data from the Portal Project. 

```{r}
time.by.species.rm <- group_by(portal, year, plot_id, plot_type) %>% count(taxon) %>% spread(key = taxon, value = n, fill = 0)
#richness <-rowSums(filter(time.by.species.rm, plot_type == "Control", plot_type == "Rodent Exclosure")# [,-c(1,2)]>0)
rich <- rowSums(time.by.species.rm[,-c(1,3)])
rich.rm1 <-filter(time.by.species.rm, plot_type == "Control", plot_type == "Rodent Exclosure") 
rich.rm2 <-as.data.frame(rich.rm1)

ar1.syn <- lme(log.abd ~ lim * day.fac, random = ~ 1 | cID, 
            correlation=corAR1(form = ~ 1 | cID),
            data=ts.abd)
#summary(ar1.syn)
#xtable(anova.lme(ar1.syn,type="sequential"), digits = 4)
set.caption("RMANOVA for -Ph Synechococcus")
pander(anova(ar1.syn))  

see 1391


# Convert tidyr object to a dataframe
time.by.species.rm <- as.data.frame(time.by.species.rm)



rm.dat <- filter(time.by.species.rm, plot_type == "Control", plot_type == "Rodent Exclosure")
rm.mod <- lme(log.abd ~ lim * day.fac, random = ~ 1 | cID, 
            correlation=corAR1(form = ~ 1 | cID),
            data=ts.abd)

```


# Some trials with calcuating abundance and richness
# time.by.species <- group_by(portal, year, plot_id) %>% count(taxon) %>% spread(key = taxon, value = n, fill = 0)
# filter(time.by.species, plot_id==2)
# abundance<-rowSums(filter(time.by.species, plot_id==2)[,-c(1,2)])
# richness<-rowSums(filter(time.by.species, plot_id==2)[,-c(1,2)]>0)
# biomass <- group_by(portal, year, plot_id) %>% summarize(rod.mass = sum(weight), na.rm = TRUE)
# p2<-filter(biomass, plot_id > 2)
# plot(rod.mass ~ year, p2, xaxt = "n", type = "l")
# 
# port <- filter(portal, plot_id == 19)
# site2biomass <- group_by(portal, plot_id, year) %>%
#   summarise(
#     sum(na.omit(weight))
#   )
# plot(site2biomass, type = "l")
# plot(site2biomass[,1], site2biomass[,3])


# Richness plots by treatment
temp <- group_by(portal, plot_type, plot_id, year) %>% count(taxon) %>% spread(key = taxon, value = n, fill = 0)
div <- vegan::diversity(temp[,-c(1:3)], metric = "richness")
temp$div <- div
tempdiv <- group_by(temp, plot_type, year) %>%
  summarise(
    mean = mean(div), 
    sd = sd(div))

plots <- ggplot(tempdiv, aes(x = year, y = mean, color = plot_type)) +
  geom_line(size = 1, show.legend = T) + 
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = .1) +
  xlim(1977, 2002) + 
  xlab("Year") + 
  ylab("Div")
plot(plots)

# Abundance plots by treatment
temp <- group_by(portal, plot_type, plot_id, year) %>% count(taxon) %>% spread(key = taxon, value = n, fill = 0)
div <- rowSums(temp[,-c(1:3)])
temp$div <- div
tempdiv <- group_by(temp, plot_type, year) %>%
  summarise(
    mean = mean(div), 
    sd = sd(div)/sqrt(n()))

plots <- ggplot(tempdiv, aes(x = year, y = mean, color = plot_type)) +
  geom_line(size = 1, show.legend = T) + 
  geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = .1) +
  xlim(1977, 2002) + 
  xlab("Year") + 
  ylab("Div")
plot(plots)



## 4) VISUALIZING TIME SERIES DATA 

```{r}
#Will's stuff
remove <- c("2000-4-31", "2000-9-31")
time.by.species <- time.by.species[!rownames(time.by.species) %in% remove, ]

time.by.species.T <- t(time.by.species)
species <- rownames(time.by.species.T)
parents <- rep(NA, each=length(species))

n <- length(species)
qual_col_pals <- brewer.pal.info[brewer.pal.info$category == 'qual',]

col_vector <- unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
col <- sample(col_vector, n)

attributes.portal <- cbind(species, parents, col) 
class(time.by.species.T) <- "numeric" 
long.form <- melt(time.by.species.T)
dates <- as.vector(long.form$Var2)
oldest <- as.Date("1977-7-16")

long.form$Var4 <- as.Date(as.character(long.form$Var2)) - oldest

keeps <- c("Var1", "Var4", 'value')
long.form <- long.form[keeps]

m.plot <- Muller.plot(attributes = attributes.portal, population.data = long.form,
                      data.method = "list", time.interval.method = "linear")

plot(0,0,axes = F)
par(mar=c(0, 0, 0, 0))
legend("right", legend = m.plot$name,col = as.character(m.plot$color),pch = 19)


```


## 4) BASIC TIME SERIES ANALYSIS
```{r}
# Let's choose a control plot
port.cont <- filter(portal, plot_id == 2)

# Now let's sum the mass of all rodents collected on a given date
summary <- port.cont %>%
  group_by(date) %>%
  summarize(rod.mass = sum(weight), na.rm = TRUE)

# Let's take a look at the plot of rodent mass over time in the plot
plot(rod.mass ~ date, summary, xaxt = "n", type = "l")
```

-- single population
-- identifying and correcting autocorrelation
-- perhaps something from the following:
http://www.statmethods.net/advstats/timeseries.html
https://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/
https://cran.r-project.org/web/views/TimeSeries.html
https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/
http://www.stat.pitt.edu/stoffer/tsa4/R_toot.htm
http://www.statoek.wiso.uni-goettingen.de/veranstaltungen/zeitreihen/sommer03/ts_r_intro.pdf

## 5) REPEATED MEASURES ANOVA
-- code from Megan
-- for univariate repsonse variable
-- perhaps revisit a diversity metric from week 2

## 6) TEMPORAL BETA DIVERSITY

The structure of an ecological community changes over time. 
We can conceptualize temporal turnover in much the same way as spatial turnover: how species change in abundance or presence over time. 


### A. Richness 
A simple measure of community change over time is how many species it gains or loses over the observed duration. 

First, we can calculate the richness in each plot, in each year. 
```{r}
portal.richness.year <- group_by(portal, year, plot_type) %>% 
  count(taxon) %>% 
  summarise(richness = n())
```

Now, let's plot this to visualize
```{r}
rich.plot <- ggplot(portal.richness.year, aes(x = year, y = richness, color = plot_type)) +
  geom_line(size = 1, show.legend = T) + 
  xlim(1977, 2002) + 
  xlab("Year") + 
  ylab("Richness")

plot(rich.plot)
```

It looks like the Control plots tend to have the highest richness, and had the highest peak richness.

### B. Turnover
A more meaningful metric takes into consideration the change in community composition of the species over time. 
Turnover gives us an idea of how similar species composition is over time: low turnover means that the composition and its relative abundances remain relatively stable through time, while high turnover suggests a highly dynamic community structure. 
Just like turnover in space, turnover can be driven by the introduction of new species or the loss of resident species. 
```{r}
# First, we will calculate the species abundances from each site over time
portal.species.abunds <- group_by(portal, year, plot_type) %>% count(taxon)

# This data.table now contains a new column `n` that represents the species counts

portal.turnover <- turnover(df = portal.species.abunds, 
                            time.var = "year", 
                            species.var = "taxon", 
                            abundance.var = "n",
                            replicate.var = "plot_type",
                            metric = "total")

portal.appearance <- turnover(df = portal.species.abunds, 
                            time.var = "year", 
                            species.var = "taxon", 
                            abundance.var = "n",
                            replicate.var = "plot_type",
                            metric = "appearance")

portal.disappearance <- turnover(df = portal.species.abunds, 
                            time.var = "year", 
                            species.var = "taxon", 
                            abundance.var = "n",
                            replicate.var = "plot_type",
                            metric = "disappearance")

# Here, we'll create one data frame with all the values
portal.turnover$metric<-"total"
names(portal.turnover)[1]="turnover"
  
portal.appearance$metric<-"appearance"
names(portal.appearance)[1]="turnover"
  
portal.disappearance$metric<-"disappearance"
names(portal.disappearance)[1]="turnover"
  
portal.allturnover<-rbind(portal.turnover, portal.appearance, portal.disappearance)
names(portal.allturnover)[2] <- "year"
```

We now have a dataframe with the three different turnover metrics calculated three different ways within each treatment. 

Let's visualize this.
```{r}
turn.plot <- ggplot(portal.allturnover, aes(x = year, y = turnover, color = metric)) +
  geom_line(size = 1, show.legend = T) + 
  facet_wrap(~plot_type) +
  xlim(1977, 2002) + 
  xlab("Year") + 
  ylab("Turnover") + 
  theme(legend.position = "bottom")
plot(turn.plot)
```

Interestingly, the Krat exclosures seem to show increasingly variable species composition, while the control plots do not. 


### C. Rank Shift
While turnover gives a measure of how dynamic a community is over time, it would also be interesting to learn how often dominance (i.e., the most abundant species) changes over time. 
If turnover is due mostly to gains and losses of rare species, with little change to the dominant members, this is not uncommon. 
However, if the community sees drastic rearrangements of community dominance (i.e., the most abundant species change ranks frequently) this could suggest something different is going on.
Mean rank shifts measure the relative change in species rank abundances.
$$
MRS = \sum_{i=1}^{n}\left(\left| R_{i, t+1} - R_{i, t} \right|\right)/n
$$
For some reason, this code chunk no longer works and returns NaN for each entry.
```{r, eval=F}
portal.abunds.full <- spread(portal.species.abunds, key = taxon, value = n, fill = 0) %>% 
  gather(key = taxon, value = n, -year, -plot_type)
portal.abunds.full$taxon <- as.factor(portal.abunds.full$taxon)
names(portal.abunds.full)[4] <- "abundance" 
portal.rankshift <- mean_rank_shift(df = portal.abunds.full, 
                               time.var = "year",
                               species.var = "taxon",
                               abundance.var = "abundance",
                               replicate.var = "plot_type")

portal.rankshift$year <- as.numeric(substr(portal.rankshift$year_pair, 6, 9))

rankshift.plot <- ggplot(portal.rankshift, aes(x = year, y = MRS)) + 
  geom_line(size = 1) + 
  xlim(1977, 2002) + 
  xlab("Year") + 
  ylab("Mean Rank Shift")

plot(rankshift.plot)
```


### D. Rate Change Interval
The temporal lag in community similarity suggests a time duration at which communities become sufficiently dissimilar to one another. 
For example, in highly dynamic systems with high species replacement and large mean rank shifts, temporal turnover may saturate after a relatively short time interval, say 5 years, after which pairwise dissimilarity values remain sufficiently different. 
Alternatively, in more stable communities, comparably large pairwise dissimmilarities may take tens if not hundreds of years.

```{r}
portal.total.abunds <- portal.species.abunds %>% group_by(year, plot_type) %>% count(wt = n)
portal.change.int1 <- rate_change_interval(portal.species.abunds,
                     time.var = "year",
                     species.var = "taxon",
                     abundance.var = "n", 
                     replicate.var = "plot_type")

rate.plot1 <- ggplot(portal.change.int1, aes(interval, distance)) + 
  geom_point() + 
  facet_wrap(~plot_type) +
  stat_smooth(method = "loess", se = F, size = 1) + 
  ylab("Euclidean Distance") + 
  xlab("Time Interval (Years)")
rate.plot1
```
Each plot looks quite different from one another. The control plot tends to keep increasing, while the Krat exclosures resemble one another and seem to saturate. The Spectab exclosure shows relatively little dissimilarity even across the whole 25-year experiment. The rodent exclosures appear to have gone through a long-term fluctuation and seem to more closely resemble each other after 25 years apart than after 10 years apart. 

But what is on the y-axis? Let's use the `help()` function to find out. 
```{r}
help(rate_change_interval)
```

We see that this function calculates the Euclidean distance between two communities. 
Remember from our discussion of beta-diversity, that Euclidean distances are not appropriate for calculating community dissimilarity because the distance between sites that share no species in common may be *shorter* than between sites that share species but in different abundances!
So, we need to transform these data with an appropriate transformation before making strong inferences about what is going on in our dataset, especially noting the hump-shaped pattern of the rodent exclosure treatment. 
Recall that one of the appropriate transformations is the Hellinger transformation, advocated by Legendre and Gallagher (2001).
The Euclidean distance calculated on the Hellinger-transformed species abundances generates the Hellinger distance. 

The Hellinger transformation is the square root of the relative abundances:
$y'_{ij} = \sqrt{\frac{y_{ij}}{y_{i+}}}$
```{r}

# In order to calculate relative abundances, we need total abundances
# First, let's count the total abundances
total.abunds <- portal.species.abunds %>% 
  group_by(year, plot_type) %>% 
  count(wt = n)  # The wt sums the values of n within a year
total.abunds # We now have a column nn that is the site total abund.

# Now, let's join these total counts with the counts for each species
portal.hellinger.transf <- inner_join(
  portal.species.abunds, total.abunds, by = c("year", "plot_type")) %>% 
  mutate(hellinger.transf = sqrt(n / nn))

# The mutate function creates a new column "hellinger.transf" 
# by taking the square root of species relative abundance
portal.hellinger.transf

# We can use this new column as our "abundance" vector
portal.change.int2 <- rate_change_interval(portal.hellinger.transf,
                     time.var = "year",
                     species.var = "taxon",
                     abundance.var = "hellinger.transf", 
                     replicate.var = "plot_type")

rate.plot2 <- ggplot(portal.change.int2, aes(interval, distance)) + 
  geom_point() + 
  facet_wrap(~plot_type) +
  stat_smooth(method = "loess", se = F, size = 1) + 
  ylab("Hellinger Distance") + 
  xlab("Time Interval (Years)")
rate.plot2
```
These figures tell a much different story than the previous ones using just the Euclidean distances alone. 
Thus, it remains important to understand the distance metrics you are using and how they are influenced by species abundances.

## 7) SYNCHRONY, or covarying species; perhaps stability, compensatory dynamics, or variance ratio?
http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12188/epdf
https://cran.r-project.org/web/packages/vrtest/vrtest.pdf

## 8) Using environmental drivers to explain temporal biodiversity data (univariate, multivariate, both?)
## loading and plotting precipitation data
## perhaps take the sum rather than mean of precip below
```{r}
precip1 <- read.table(file = "./data/Portal_precipitation_19801989.csv", header = T, sep = ",")
precip2 <- read.table(file = "./data/Portal_precipitation_19892002.csv", header = T, sep = ",")

precip.month <- unite(precip1, col = date, c(Year, Month), sep = ".", remove = F)
precip.month$date <- as.Date(precip.month$date, "%Y-%m")
precip.month$date <- as.numeric(precip.month$date)

precip2 <- read.table(file = "./data/Portal_precipitation_19892002.csv", header = T, sep = ",")
precip2 <- unite(precip2, col = date, c(Year, Month, Day, Hour), sep = "-", remove = F)
parse_date_time(precip2$date, "%y-%m-%d-%H%M")

monthly.precip <- group_by(precip2, Year, Month) %>%
  summarise(mean = mean(Precipitation))
monthly.precip$date <- unite(monthly.precip, col = date, c(Year, Month), sep = ".")
plot(monthly.precip$date, monthly.precip$mean)
```